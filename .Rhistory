knitr::opts_chunk$set(echo = TRUE)
library(httr2)
library(dplyr)
library(stringr)
library(tibble)
clean_record <- function(x) {
# 1️⃣ NULL → NA
x <- purrr::map(x, ~ if (is.null(.x)) NA else .x)
# 2️⃣ 把「會爆炸的 list 欄位」壓成字串
list_cols <- c("subjectCode", "surveyCode", "corrections")
for (col in intersect(names(x), list_cols)) {
x[[col]] <- paste(unlist(x[[col]]), collapse = ",")
if (x[[col]] == "") x[[col]] <- NA
}
# 3️⃣ 確保每個欄位都是 length-1 atomic vector
x <- purrr::map(x, ~ {
if (length(.x) == 1) .x else paste(.x, collapse = ",")
})
tibble::as_tibble(x)
}
library(httr2)
library(dplyr)
library(purrr)
library(tibble)
library(stringr)
# --- helper: GET JSON ---
wds_get <- function(url) {
resp <- request(url) |>
req_headers("Accept" = "application/json") |>
req_perform()
if (resp_status(resp) >= 400) {
stop("HTTP ", resp_status(resp))
}
resp_body_json(resp)
}
# --- 1) get all cubes list (Lite) ---
j <- wds_get("https://www150.statcan.gc.ca/t1/wds/rest/getAllCubesListLite")
# --- 2) SAFE conversion ---
cubes <- purrr::map_dfr(j, clean_record)
# --- 3) sanity check ---
glimpse(cubes)
library(httr2)
library(jsonlite)
wds_post <- function(url, body) {
resp <- request(url) |>
# 有些政府站會對沒有 UA 的 request 比較敏感
req_user_agent("DATA534-WDS-wrapper/0.1 (httr2)") |>
# Accept 放寬：有些 API 不吃 application/json 但會回 text/json
req_headers(
"Accept" = "application/json, text/json, */*",
"Content-Type" = "application/json"
) |>
req_method("POST") |>
# 用 jsonlite 自己序列化，避免 req_body_json() 產生的細節差異
req_body_raw(jsonlite::toJSON(body, auto_unbox = TRUE), type = "application/json") |>
req_perform()
if (resp_status(resp) >= 400) {
stop("HTTP ", resp_status(resp), ": ", resp_body_string(resp))
}
resp_body_json(resp)
}
library(dplyr)
library(stringr)
wait_cubes <- cubes |>
mutate(title = str_to_lower(cubeTitleEn)) |>
filter(
str_detect(title, "wait|waiting|access|treatment") &
str_detect(title, "health|hospital|surgery|medical")
) |>
select(
productId,
cansimId,
cubeTitleEn,
cubeStartDate,
cubeEndDate,
archived
) |>
arrange(desc(cubeEndDate))
wait_cubes
meta <- wds_post(
"https://www150.statcan.gc.ca/t1/wds/rest/getCubeMetadata",
list(productId = 41100081)
)
pid <- 41100081
dl <- wds_get(glue::glue(
"https://www150.statcan.gc.ca/t1/wds/rest/getFullTableDownloadCSV/{pid}/en"
))
# list(status="SUCCESS", object="https://.../n1/tbl/csv/XXXX-eng.zip")
zip_url <- dl$object
zip_url
temp_zip <- tempfile(fileext = ".zip")
download.file(
url = zip_url,
destfile = temp_zip,
mode = "wb"
)
file.exists(temp_zip)
temp_dir <- tempdir()
unzip(
zipfile = temp_zip,
exdir = temp_dir
)
list.files(temp_dir)
library(readr)
data_path <- file.path(temp_dir, "13100962.csv")
wait_data <- read_csv(data_path)
library(readr)
data_path <- file.path(temp_dir, "41100081.csv)
wait_data <- read_csv(data_path)
list.files(temp_dir)
library(readr)
data_path <- file.path(temp_dir, "41100081.csv)
wait_data <- read_csv(data_path)
library(readr)
data_path <- file.path(temp_dir, "41100081.csv")
wait_data <- read_csv(data_path)
glimpse(wait_data)
unique(wait_data$REF_DATE)
library(dplyr)
cat_cols <- wait_data %>%
select(where(is.character)) %>%
names()
cat_cols
library(purrr)
cat_summary <- map_df(
cat_cols,
~ tibble(
column = .x,
n_unique = n_distinct(wait_data[[.x]])
)
)
cat_summary %>% arrange(desc(n_unique))
sort(unique(wait_data$GEO))
unique(wait_data$Indicators)
data_path_2 <- file.path(temp_dir, "13100962_MetaData.csv")
wait_data_2 <- read_csv(data_path_2)
data_path_2 <- file.path(temp_dir, "41100081_MetaData.csv")
wait_data_2 <- read_csv(data_path_2)
glimpse(wait_data_2)
